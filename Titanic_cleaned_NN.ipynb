{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zrjL7hEzZJQA",
    "outputId": "bbaf0da7-2789-4e35-c44a-abad4bc32140"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.kaggle.com/jamesleslie/titanic-neural-network-for-beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohLCVaD0ZYRx"
   },
   "outputs": [],
   "source": [
    "#Importing data into google Colab using Github raw content\n",
    "#reference : https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92\n",
    "# dataset_url = \"https://raw.githubusercontent.com/soumoks/Titanic-Kaggle-Competition/master/cleaned_train.csv\"\n",
    "df = pd.read_csv('cleaned_train_test.csv',index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>1.124265</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>-1.546098</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>1.075478</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>1.124265</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>-1.546098</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>2.866573</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>1.915057</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>-1.546098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>1.971025</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>0.333474</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sex     Title  AgeGroup      Fare  Relatives  Embarked  \\\n",
       "PassengerId                                                                \n",
       "1           -0.743497 -0.715617  0.353004 -1.248109   0.073352 -0.603436   \n",
       "2            1.344995  0.179930  0.353004  1.124265   0.073352  0.927373   \n",
       "3            1.344995  1.075478 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "4            1.344995  0.179930  0.353004  1.124265   0.073352 -0.603436   \n",
       "5           -0.743497 -0.715617  0.353004 -0.457318  -0.558346 -0.603436   \n",
       "...               ...       ...       ...       ...        ...       ...   \n",
       "1305        -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "1306         1.344995  2.866573  0.353004  1.915057  -0.558346  0.927373   \n",
       "1307        -0.743497 -0.715617  0.353004 -1.248109  -0.558346 -0.603436   \n",
       "1308        -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "1309        -0.743497  1.971025 -1.091002  0.333474   0.705051  0.927373   \n",
       "\n",
       "               Pclass  Survived  \n",
       "PassengerId                      \n",
       "1            0.841916       0.0  \n",
       "2           -1.546098       1.0  \n",
       "3            0.841916       1.0  \n",
       "4           -1.546098       1.0  \n",
       "5            0.841916       0.0  \n",
       "...               ...       ...  \n",
       "1305         0.841916       NaN  \n",
       "1306        -1.546098       NaN  \n",
       "1307         0.841916       NaN  \n",
       "1308         0.841916       NaN  \n",
       "1309         0.841916       NaN  \n",
       "\n",
       "[1309 rows x 8 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ji5OpLNIZjmK"
   },
   "outputs": [],
   "source": [
    "labels = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[:891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJ5bpnvpaUC2"
   },
   "outputs": [],
   "source": [
    "labels = labels.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "5      0\n",
       "      ..\n",
       "887    0\n",
       "888    1\n",
       "889    0\n",
       "890    1\n",
       "891    0\n",
       "Name: Survived, Length: 891, dtype: int32"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2aVEujraYOT"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Survived'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "E0TnLmpvac09",
    "outputId": "05d29f7d-f704-438d-8c05-60d0662d5229"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>1.124265</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>-1.546098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>1.075478</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>1.124265</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>-1.546098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>3.762120</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>-0.352091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>1.075478</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>0.333474</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>-1.546098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>1.075478</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>0.333474</td>\n",
       "      <td>1.336749</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>0.333474</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>-1.546098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>2.458182</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sex     Title  AgeGroup      Fare  Relatives  Embarked  \\\n",
       "PassengerId                                                                \n",
       "1           -0.743497 -0.715617  0.353004 -1.248109   0.073352 -0.603436   \n",
       "2            1.344995  0.179930  0.353004  1.124265   0.073352  0.927373   \n",
       "3            1.344995  1.075478 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "4            1.344995  0.179930  0.353004  1.124265   0.073352 -0.603436   \n",
       "5           -0.743497 -0.715617  0.353004 -0.457318  -0.558346 -0.603436   \n",
       "...               ...       ...       ...       ...        ...       ...   \n",
       "887         -0.743497  3.762120 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "888          1.344995  1.075478  0.353004  0.333474  -0.558346 -0.603436   \n",
       "889          1.344995  1.075478  0.353004  0.333474   1.336749 -0.603436   \n",
       "890         -0.743497 -0.715617 -1.091002  0.333474  -0.558346  0.927373   \n",
       "891         -0.743497 -0.715617  0.353004 -1.248109  -0.558346  2.458182   \n",
       "\n",
       "               Pclass  \n",
       "PassengerId            \n",
       "1            0.841916  \n",
       "2           -1.546098  \n",
       "3            0.841916  \n",
       "4           -1.546098  \n",
       "5            0.841916  \n",
       "...               ...  \n",
       "887         -0.352091  \n",
       "888         -1.546098  \n",
       "889          0.841916  \n",
       "890         -1.546098  \n",
       "891          0.841916  \n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>2.458182</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>1.797009</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>2.458182</td>\n",
       "      <td>-0.352091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>2.866573</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>1.915057</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>-1.546098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>1.971025</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>0.333474</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sex     Title  AgeGroup      Fare  Relatives  Embarked  \\\n",
       "PassengerId                                                                \n",
       "892         -0.743497 -0.715617  0.353004 -1.248109  -0.558346  2.458182   \n",
       "893          1.344995  0.179930  1.797009 -1.248109   0.073352 -0.603436   \n",
       "894         -0.743497 -0.715617 -1.091002 -0.457318  -0.558346  2.458182   \n",
       "895         -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "896          1.344995  0.179930  0.353004 -0.457318   0.705051 -0.603436   \n",
       "...               ...       ...       ...       ...        ...       ...   \n",
       "1305        -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "1306         1.344995  2.866573  0.353004  1.915057  -0.558346  0.927373   \n",
       "1307        -0.743497 -0.715617  0.353004 -1.248109  -0.558346 -0.603436   \n",
       "1308        -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "1309        -0.743497  1.971025 -1.091002  0.333474   0.705051  0.927373   \n",
       "\n",
       "               Pclass  Survived  \n",
       "PassengerId                      \n",
       "892          0.841916       NaN  \n",
       "893          0.841916       NaN  \n",
       "894         -0.352091       NaN  \n",
       "895          0.841916       NaN  \n",
       "896          0.841916       NaN  \n",
       "...               ...       ...  \n",
       "1305         0.841916       NaN  \n",
       "1306        -1.546098       NaN  \n",
       "1307         0.841916       NaN  \n",
       "1308         0.841916       NaN  \n",
       "1309         0.841916       NaN  \n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['Survived'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>2.458182</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>1.797009</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>2.458182</td>\n",
       "      <td>-0.352091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>2.866573</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>1.915057</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>-1.546098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>1.971025</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>0.333474</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>0.841916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sex     Title  AgeGroup      Fare  Relatives  Embarked  \\\n",
       "PassengerId                                                                \n",
       "892         -0.743497 -0.715617  0.353004 -1.248109  -0.558346  2.458182   \n",
       "893          1.344995  0.179930  1.797009 -1.248109   0.073352 -0.603436   \n",
       "894         -0.743497 -0.715617 -1.091002 -0.457318  -0.558346  2.458182   \n",
       "895         -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "896          1.344995  0.179930  0.353004 -0.457318   0.705051 -0.603436   \n",
       "...               ...       ...       ...       ...        ...       ...   \n",
       "1305        -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "1306         1.344995  2.866573  0.353004  1.915057  -0.558346  0.927373   \n",
       "1307        -0.743497 -0.715617  0.353004 -1.248109  -0.558346 -0.603436   \n",
       "1308        -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "1309        -0.743497  1.971025 -1.091002  0.333474   0.705051  0.927373   \n",
       "\n",
       "               Pclass  \n",
       "PassengerId            \n",
       "892          0.841916  \n",
       "893          0.841916  \n",
       "894         -0.352091  \n",
       "895          0.841916  \n",
       "896          0.841916  \n",
       "...               ...  \n",
       "1305         0.841916  \n",
       "1306        -1.546098  \n",
       "1307         0.841916  \n",
       "1308         0.841916  \n",
       "1309         0.841916  \n",
       "\n",
       "[418 rows x 7 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lyLvmRH7bQDJ"
   },
   "outputs": [],
   "source": [
    "#### Preprocessing is required for neural networks to convert it into a single dimensional array\n",
    "#might not be required based on the below article\n",
    "# https://www.kaggle.com/jamesleslie/titanic-neural-network-for-beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "D9-mpUuLamh8",
    "outputId": "0f5533e7-1db4-4545-938e-697e4f361996"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "7e_1iKmsJfJE",
    "outputId": "f6f303fc-b573-4c74-bd9c-8dc0647f2896"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(8, activation='relu', input_shape=(7,)))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  # output layer\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjWWhDJDJfux"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 8)                 64        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 7)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/200\n",
      "712/712 [==============================] - 0s 550us/step - loss: 0.8355 - accuracy: 0.4284 - val_loss: 0.8098 - val_accuracy: 0.4078\n",
      "Epoch 2/200\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.7514 - accuracy: 0.5169 - val_loss: 0.7271 - val_accuracy: 0.5866\n",
      "Epoch 3/200\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.7006 - accuracy: 0.6081 - val_loss: 0.6682 - val_accuracy: 0.6313\n",
      "Epoch 4/200\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.6544 - accuracy: 0.6615 - val_loss: 0.6225 - val_accuracy: 0.7430\n",
      "Epoch 5/200\n",
      "712/712 [==============================] - 0s 48us/step - loss: 0.6239 - accuracy: 0.6615 - val_loss: 0.5817 - val_accuracy: 0.7374\n",
      "Epoch 6/200\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.5993 - accuracy: 0.7022 - val_loss: 0.5466 - val_accuracy: 0.7542\n",
      "Epoch 7/200\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5799 - accuracy: 0.7289 - val_loss: 0.5163 - val_accuracy: 0.7598\n",
      "Epoch 8/200\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.5491 - accuracy: 0.7374 - val_loss: 0.4898 - val_accuracy: 0.7654\n",
      "Epoch 9/200\n",
      "712/712 [==============================] - 0s 87us/step - loss: 0.5325 - accuracy: 0.7472 - val_loss: 0.4694 - val_accuracy: 0.7709\n",
      "Epoch 10/200\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.5276 - accuracy: 0.7598 - val_loss: 0.4525 - val_accuracy: 0.7709\n",
      "Epoch 11/200\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.5120 - accuracy: 0.7640 - val_loss: 0.4379 - val_accuracy: 0.7933\n",
      "Epoch 12/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.5067 - accuracy: 0.7697 - val_loss: 0.4277 - val_accuracy: 0.7989\n",
      "Epoch 13/200\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4982 - accuracy: 0.7697 - val_loss: 0.4185 - val_accuracy: 0.8156\n",
      "Epoch 14/200\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4811 - accuracy: 0.7654 - val_loss: 0.4121 - val_accuracy: 0.8156\n",
      "Epoch 15/200\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4886 - accuracy: 0.7683 - val_loss: 0.4061 - val_accuracy: 0.8045\n",
      "Epoch 16/200\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4750 - accuracy: 0.7767 - val_loss: 0.4009 - val_accuracy: 0.8045\n",
      "Epoch 17/200\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4776 - accuracy: 0.7683 - val_loss: 0.3969 - val_accuracy: 0.8045\n",
      "Epoch 18/200\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.75 - 0s 83us/step - loss: 0.4726 - accuracy: 0.7711 - val_loss: 0.3925 - val_accuracy: 0.8101\n",
      "Epoch 19/200\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4712 - accuracy: 0.7683 - val_loss: 0.3896 - val_accuracy: 0.8156\n",
      "Epoch 20/200\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4474 - accuracy: 0.7921 - val_loss: 0.3868 - val_accuracy: 0.8156\n",
      "Epoch 21/200\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4536 - accuracy: 0.7879 - val_loss: 0.3839 - val_accuracy: 0.8156\n",
      "Epoch 22/200\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4553 - accuracy: 0.7837 - val_loss: 0.3813 - val_accuracy: 0.8156\n",
      "Epoch 23/200\n",
      "712/712 [==============================] - 0s 50us/step - loss: 0.4532 - accuracy: 0.8062 - val_loss: 0.3797 - val_accuracy: 0.8156\n",
      "Epoch 24/200\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4490 - accuracy: 0.7992 - val_loss: 0.3787 - val_accuracy: 0.8212\n",
      "Epoch 25/200\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4463 - accuracy: 0.7907 - val_loss: 0.3765 - val_accuracy: 0.8212\n",
      "Epoch 26/200\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4465 - accuracy: 0.7963 - val_loss: 0.3768 - val_accuracy: 0.8156\n",
      "Epoch 27/200\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4519 - accuracy: 0.8104 - val_loss: 0.3751 - val_accuracy: 0.8156\n",
      "Epoch 28/200\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4275 - accuracy: 0.8132 - val_loss: 0.3741 - val_accuracy: 0.8156\n",
      "Epoch 29/200\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4346 - accuracy: 0.8048 - val_loss: 0.3738 - val_accuracy: 0.8156\n",
      "Epoch 30/200\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4468 - accuracy: 0.8006 - val_loss: 0.3742 - val_accuracy: 0.8268\n",
      "Epoch 31/200\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4509 - accuracy: 0.7978 - val_loss: 0.3731 - val_accuracy: 0.8268\n",
      "Epoch 32/200\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4376 - accuracy: 0.8006 - val_loss: 0.3723 - val_accuracy: 0.8268\n",
      "Epoch 33/200\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4403 - accuracy: 0.8076 - val_loss: 0.3719 - val_accuracy: 0.8268\n",
      "Epoch 34/200\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4517 - accuracy: 0.7978 - val_loss: 0.3738 - val_accuracy: 0.8268\n",
      "Epoch 35/200\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4254 - accuracy: 0.8090 - val_loss: 0.3740 - val_accuracy: 0.8268\n",
      "Epoch 36/200\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4268 - accuracy: 0.8034 - val_loss: 0.3727 - val_accuracy: 0.8268\n",
      "Epoch 37/200\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4295 - accuracy: 0.8160 - val_loss: 0.3720 - val_accuracy: 0.8268\n",
      "Epoch 38/200\n",
      "712/712 [==============================] - 0s 46us/step - loss: 0.4345 - accuracy: 0.8188 - val_loss: 0.3704 - val_accuracy: 0.8268\n",
      "Epoch 39/200\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4348 - accuracy: 0.8090 - val_loss: 0.3699 - val_accuracy: 0.8268\n",
      "Epoch 40/200\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4283 - accuracy: 0.8076 - val_loss: 0.3693 - val_accuracy: 0.8268\n",
      "Epoch 41/200\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4300 - accuracy: 0.8104 - val_loss: 0.3694 - val_accuracy: 0.8324\n",
      "Epoch 42/200\n",
      "712/712 [==============================] - 0s 54us/step - loss: 0.4358 - accuracy: 0.8048 - val_loss: 0.3689 - val_accuracy: 0.8324\n",
      "Epoch 43/200\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4297 - accuracy: 0.8020 - val_loss: 0.3694 - val_accuracy: 0.8324\n",
      "Epoch 44/200\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4305 - accuracy: 0.8146 - val_loss: 0.3686 - val_accuracy: 0.8324\n",
      "Epoch 45/200\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4274 - accuracy: 0.8118 - val_loss: 0.3678 - val_accuracy: 0.8380\n",
      "Epoch 46/200\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4304 - accuracy: 0.8160 - val_loss: 0.3665 - val_accuracy: 0.8492\n",
      "Epoch 47/200\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4313 - accuracy: 0.8104 - val_loss: 0.3662 - val_accuracy: 0.8492\n",
      "Epoch 48/200\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4417 - accuracy: 0.8076 - val_loss: 0.3678 - val_accuracy: 0.8492\n",
      "Epoch 49/200\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4352 - accuracy: 0.8132 - val_loss: 0.3668 - val_accuracy: 0.8492\n",
      "Epoch 50/200\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4226 - accuracy: 0.8301 - val_loss: 0.3680 - val_accuracy: 0.8492\n",
      "Epoch 51/200\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4267 - accuracy: 0.8006 - val_loss: 0.3668 - val_accuracy: 0.8492\n",
      "Epoch 52/200\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4272 - accuracy: 0.8062 - val_loss: 0.3662 - val_accuracy: 0.8492\n",
      "Epoch 53/200\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.4224 - accuracy: 0.8216 - val_loss: 0.3656 - val_accuracy: 0.8547\n",
      "Epoch 54/200\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4312 - accuracy: 0.8118 - val_loss: 0.3662 - val_accuracy: 0.8492\n",
      "Epoch 55/200\n",
      "712/712 [==============================] - 0s 48us/step - loss: 0.4275 - accuracy: 0.8090 - val_loss: 0.3678 - val_accuracy: 0.8492\n",
      "Epoch 56/200\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4203 - accuracy: 0.8272 - val_loss: 0.3672 - val_accuracy: 0.8492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4281 - accuracy: 0.8244 - val_loss: 0.3676 - val_accuracy: 0.8492\n",
      "Epoch 58/200\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4355 - accuracy: 0.8090 - val_loss: 0.3678 - val_accuracy: 0.8492\n",
      "Epoch 59/200\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4258 - accuracy: 0.8230 - val_loss: 0.3674 - val_accuracy: 0.8492\n",
      "Epoch 60/200\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4311 - accuracy: 0.8104 - val_loss: 0.3667 - val_accuracy: 0.8547\n",
      "Epoch 61/200\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4259 - accuracy: 0.8132 - val_loss: 0.3662 - val_accuracy: 0.8492\n",
      "Epoch 62/200\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4258 - accuracy: 0.8188 - val_loss: 0.3649 - val_accuracy: 0.8436\n",
      "Epoch 63/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4327 - accuracy: 0.8146 - val_loss: 0.3652 - val_accuracy: 0.8436\n",
      "Epoch 64/200\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4178 - accuracy: 0.8357 - val_loss: 0.3657 - val_accuracy: 0.8436\n",
      "Epoch 65/200\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4228 - accuracy: 0.8146 - val_loss: 0.3658 - val_accuracy: 0.8436\n",
      "Epoch 66/200\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4320 - accuracy: 0.8146 - val_loss: 0.3647 - val_accuracy: 0.8436\n",
      "Epoch 67/200\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4234 - accuracy: 0.8244 - val_loss: 0.3641 - val_accuracy: 0.8436\n",
      "Epoch 68/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4265 - accuracy: 0.8216 - val_loss: 0.3647 - val_accuracy: 0.8436\n",
      "Epoch 69/200\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4289 - accuracy: 0.8258 - val_loss: 0.3649 - val_accuracy: 0.8436\n",
      "Epoch 70/200\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4202 - accuracy: 0.8188 - val_loss: 0.3652 - val_accuracy: 0.8380\n",
      "Epoch 71/200\n",
      "712/712 [==============================] - 0s 52us/step - loss: 0.4280 - accuracy: 0.8146 - val_loss: 0.3649 - val_accuracy: 0.8380\n",
      "Epoch 72/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4297 - accuracy: 0.8174 - val_loss: 0.3656 - val_accuracy: 0.8380\n",
      "Epoch 73/200\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4256 - accuracy: 0.8216 - val_loss: 0.3648 - val_accuracy: 0.8380\n",
      "Epoch 74/200\n",
      "712/712 [==============================] - 0s 52us/step - loss: 0.4267 - accuracy: 0.8132 - val_loss: 0.3651 - val_accuracy: 0.8380\n",
      "Epoch 75/200\n",
      "712/712 [==============================] - 0s 58us/step - loss: 0.4283 - accuracy: 0.8287 - val_loss: 0.3648 - val_accuracy: 0.8380\n",
      "Epoch 76/200\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4169 - accuracy: 0.8272 - val_loss: 0.3637 - val_accuracy: 0.8380\n",
      "Epoch 77/200\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4287 - accuracy: 0.8160 - val_loss: 0.3637 - val_accuracy: 0.8380\n",
      "Epoch 78/200\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4081 - accuracy: 0.8287 - val_loss: 0.3638 - val_accuracy: 0.8380\n",
      "Epoch 79/200\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4209 - accuracy: 0.8258 - val_loss: 0.3631 - val_accuracy: 0.8380\n",
      "Epoch 80/200\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4213 - accuracy: 0.8258 - val_loss: 0.3626 - val_accuracy: 0.8380\n",
      "Epoch 81/200\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4426 - accuracy: 0.8174 - val_loss: 0.3628 - val_accuracy: 0.8380\n",
      "Epoch 82/200\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4273 - accuracy: 0.8202 - val_loss: 0.3630 - val_accuracy: 0.8380\n",
      "Epoch 83/200\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.4340 - accuracy: 0.8132 - val_loss: 0.3643 - val_accuracy: 0.8380\n",
      "Epoch 84/200\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.4348 - accuracy: 0.8315 - val_loss: 0.3655 - val_accuracy: 0.8380\n",
      "Epoch 85/200\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4145 - accuracy: 0.8258 - val_loss: 0.3650 - val_accuracy: 0.8380\n",
      "Epoch 86/200\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4300 - accuracy: 0.8315 - val_loss: 0.3653 - val_accuracy: 0.8380\n",
      "Epoch 87/200\n",
      "712/712 [==============================] - 0s 45us/step - loss: 0.4195 - accuracy: 0.8244 - val_loss: 0.3652 - val_accuracy: 0.8380\n",
      "Epoch 88/200\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4117 - accuracy: 0.8287 - val_loss: 0.3642 - val_accuracy: 0.8380\n",
      "Epoch 89/200\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4260 - accuracy: 0.8202 - val_loss: 0.3634 - val_accuracy: 0.8380\n",
      "Epoch 90/200\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4264 - accuracy: 0.8132 - val_loss: 0.3624 - val_accuracy: 0.8436\n",
      "Epoch 91/200\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4227 - accuracy: 0.8230 - val_loss: 0.3624 - val_accuracy: 0.8380\n",
      "Epoch 92/200\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4287 - accuracy: 0.8160 - val_loss: 0.3642 - val_accuracy: 0.8380\n",
      "Epoch 93/200\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4258 - accuracy: 0.8244 - val_loss: 0.3639 - val_accuracy: 0.8436\n",
      "Epoch 94/200\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4192 - accuracy: 0.8357 - val_loss: 0.3642 - val_accuracy: 0.8436\n",
      "Epoch 95/200\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4230 - accuracy: 0.8272 - val_loss: 0.3645 - val_accuracy: 0.8436\n",
      "Epoch 96/200\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4217 - accuracy: 0.8315 - val_loss: 0.3636 - val_accuracy: 0.8436\n",
      "Epoch 97/200\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4159 - accuracy: 0.8301 - val_loss: 0.3638 - val_accuracy: 0.8380\n",
      "Epoch 98/200\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4168 - accuracy: 0.8287 - val_loss: 0.3631 - val_accuracy: 0.8380\n",
      "Epoch 99/200\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4216 - accuracy: 0.8343 - val_loss: 0.3620 - val_accuracy: 0.8380\n",
      "Epoch 100/200\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4201 - accuracy: 0.8216 - val_loss: 0.3623 - val_accuracy: 0.8380\n",
      "Epoch 101/200\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4175 - accuracy: 0.8216 - val_loss: 0.3636 - val_accuracy: 0.8380\n",
      "Epoch 102/200\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4244 - accuracy: 0.8146 - val_loss: 0.3644 - val_accuracy: 0.8380\n",
      "Epoch 103/200\n",
      "712/712 [==============================] - 0s 44us/step - loss: 0.4081 - accuracy: 0.8272 - val_loss: 0.3636 - val_accuracy: 0.8380\n",
      "Epoch 104/200\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4257 - accuracy: 0.8258 - val_loss: 0.3638 - val_accuracy: 0.8380\n",
      "Epoch 105/200\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4099 - accuracy: 0.8287 - val_loss: 0.3640 - val_accuracy: 0.8324\n",
      "Epoch 106/200\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4132 - accuracy: 0.8230 - val_loss: 0.3633 - val_accuracy: 0.8380\n",
      "Epoch 107/200\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4247 - accuracy: 0.8329 - val_loss: 0.3639 - val_accuracy: 0.8380\n",
      "Epoch 108/200\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4192 - accuracy: 0.8258 - val_loss: 0.3648 - val_accuracy: 0.8380\n",
      "Epoch 109/200\n",
      "712/712 [==============================] - 0s 66us/step - loss: 0.4190 - accuracy: 0.8258 - val_loss: 0.3640 - val_accuracy: 0.8380\n",
      "Epoch 110/200\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4119 - accuracy: 0.8216 - val_loss: 0.3632 - val_accuracy: 0.8380\n",
      "Epoch 111/200\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4181 - accuracy: 0.8188 - val_loss: 0.3630 - val_accuracy: 0.8380\n",
      "Epoch 112/200\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4211 - accuracy: 0.8272 - val_loss: 0.3626 - val_accuracy: 0.8436\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 63us/step - loss: 0.4166 - accuracy: 0.8315 - val_loss: 0.3626 - val_accuracy: 0.8436\n",
      "Epoch 114/200\n",
      "712/712 [==============================] - 0s 71us/step - loss: 0.4175 - accuracy: 0.8315 - val_loss: 0.3644 - val_accuracy: 0.8380\n",
      "Epoch 115/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4169 - accuracy: 0.8258 - val_loss: 0.3642 - val_accuracy: 0.8436\n",
      "Epoch 116/200\n",
      "712/712 [==============================] - 0s 53us/step - loss: 0.4084 - accuracy: 0.8272 - val_loss: 0.3640 - val_accuracy: 0.8436\n",
      "Epoch 117/200\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4153 - accuracy: 0.8287 - val_loss: 0.3655 - val_accuracy: 0.8436\n",
      "Epoch 118/200\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4235 - accuracy: 0.8174 - val_loss: 0.3644 - val_accuracy: 0.8380\n",
      "Epoch 119/200\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.4075 - accuracy: 0.8301 - val_loss: 0.3640 - val_accuracy: 0.8380\n",
      "Epoch 120/200\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4085 - accuracy: 0.8315 - val_loss: 0.3651 - val_accuracy: 0.8324\n",
      "Epoch 121/200\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.4171 - accuracy: 0.8118 - val_loss: 0.3649 - val_accuracy: 0.8268\n",
      "Epoch 122/200\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4248 - accuracy: 0.8258 - val_loss: 0.3650 - val_accuracy: 0.8380\n",
      "Epoch 123/200\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4169 - accuracy: 0.8272 - val_loss: 0.3652 - val_accuracy: 0.8380\n",
      "Epoch 124/200\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4051 - accuracy: 0.8371 - val_loss: 0.3645 - val_accuracy: 0.8380\n",
      "Epoch 125/200\n",
      "712/712 [==============================] - 0s 84us/step - loss: 0.4150 - accuracy: 0.8315 - val_loss: 0.3631 - val_accuracy: 0.8380\n",
      "Epoch 126/200\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4160 - accuracy: 0.8230 - val_loss: 0.3622 - val_accuracy: 0.8436\n",
      "Epoch 127/200\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4127 - accuracy: 0.8272 - val_loss: 0.3633 - val_accuracy: 0.8380\n",
      "Epoch 128/200\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4121 - accuracy: 0.8230 - val_loss: 0.3637 - val_accuracy: 0.8380\n",
      "Epoch 129/200\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.4050 - accuracy: 0.8329 - val_loss: 0.3634 - val_accuracy: 0.8380\n",
      "Epoch 130/200\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4140 - accuracy: 0.8301 - val_loss: 0.3627 - val_accuracy: 0.8380\n",
      "Epoch 131/200\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4129 - accuracy: 0.8315 - val_loss: 0.3634 - val_accuracy: 0.8380\n",
      "Epoch 132/200\n",
      "712/712 [==============================] - 0s 46us/step - loss: 0.4166 - accuracy: 0.8315 - val_loss: 0.3640 - val_accuracy: 0.8380\n",
      "Epoch 133/200\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4128 - accuracy: 0.8357 - val_loss: 0.3632 - val_accuracy: 0.8324\n",
      "Epoch 134/200\n",
      "712/712 [==============================] - 0s 72us/step - loss: 0.4197 - accuracy: 0.8202 - val_loss: 0.3640 - val_accuracy: 0.8380\n",
      "Epoch 135/200\n",
      "712/712 [==============================] - 0s 51us/step - loss: 0.4254 - accuracy: 0.8272 - val_loss: 0.3640 - val_accuracy: 0.8324\n",
      "Epoch 136/200\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4179 - accuracy: 0.8174 - val_loss: 0.3640 - val_accuracy: 0.8380\n",
      "Epoch 137/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4065 - accuracy: 0.8272 - val_loss: 0.3630 - val_accuracy: 0.8324\n",
      "Epoch 138/200\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4217 - accuracy: 0.8216 - val_loss: 0.3630 - val_accuracy: 0.8436\n",
      "Epoch 139/200\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4195 - accuracy: 0.8301 - val_loss: 0.3638 - val_accuracy: 0.8324\n",
      "Epoch 140/200\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4172 - accuracy: 0.8230 - val_loss: 0.3635 - val_accuracy: 0.8324\n",
      "Epoch 141/200\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4063 - accuracy: 0.8343 - val_loss: 0.3643 - val_accuracy: 0.8324\n",
      "Epoch 142/200\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.4092 - accuracy: 0.8287 - val_loss: 0.3634 - val_accuracy: 0.8324\n",
      "Epoch 143/200\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.4178 - accuracy: 0.8287 - val_loss: 0.3633 - val_accuracy: 0.8212\n",
      "Epoch 144/200\n",
      "712/712 [==============================] - 0s 46us/step - loss: 0.4050 - accuracy: 0.8343 - val_loss: 0.3623 - val_accuracy: 0.8324\n",
      "Epoch 145/200\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4108 - accuracy: 0.8258 - val_loss: 0.3628 - val_accuracy: 0.8268\n",
      "Epoch 146/200\n",
      "712/712 [==============================] - 0s 48us/step - loss: 0.4225 - accuracy: 0.8146 - val_loss: 0.3634 - val_accuracy: 0.8380\n",
      "Epoch 147/200\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4224 - accuracy: 0.8258 - val_loss: 0.3634 - val_accuracy: 0.8380\n",
      "Epoch 148/200\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4138 - accuracy: 0.8287 - val_loss: 0.3641 - val_accuracy: 0.8380\n",
      "Epoch 149/200\n",
      "712/712 [==============================] - 0s 63us/step - loss: 0.4111 - accuracy: 0.8315 - val_loss: 0.3631 - val_accuracy: 0.8380\n",
      "Epoch 150/200\n",
      "712/712 [==============================] - 0s 41us/step - loss: 0.4166 - accuracy: 0.8343 - val_loss: 0.3623 - val_accuracy: 0.8436\n",
      "Epoch 151/200\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4144 - accuracy: 0.8230 - val_loss: 0.3627 - val_accuracy: 0.8436\n",
      "Epoch 152/200\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4208 - accuracy: 0.8202 - val_loss: 0.3635 - val_accuracy: 0.8380\n",
      "Epoch 153/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4114 - accuracy: 0.8287 - val_loss: 0.3639 - val_accuracy: 0.8380\n",
      "Epoch 154/200\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4189 - accuracy: 0.8202 - val_loss: 0.3645 - val_accuracy: 0.8268\n",
      "Epoch 155/200\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.4100 - accuracy: 0.8287 - val_loss: 0.3638 - val_accuracy: 0.8436\n",
      "Epoch 156/200\n",
      "712/712 [==============================] - 0s 39us/step - loss: 0.4138 - accuracy: 0.8287 - val_loss: 0.3642 - val_accuracy: 0.8380\n",
      "Epoch 157/200\n",
      "712/712 [==============================] - 0s 59us/step - loss: 0.4107 - accuracy: 0.8287 - val_loss: 0.3637 - val_accuracy: 0.8436\n",
      "Epoch 158/200\n",
      "712/712 [==============================] - 0s 83us/step - loss: 0.4159 - accuracy: 0.8272 - val_loss: 0.3625 - val_accuracy: 0.8380\n",
      "Epoch 159/200\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4072 - accuracy: 0.8329 - val_loss: 0.3624 - val_accuracy: 0.8436\n",
      "Epoch 160/200\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4168 - accuracy: 0.8357 - val_loss: 0.3622 - val_accuracy: 0.8492\n",
      "Epoch 161/200\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4155 - accuracy: 0.8216 - val_loss: 0.3634 - val_accuracy: 0.8436\n",
      "Epoch 162/200\n",
      "712/712 [==============================] - 0s 79us/step - loss: 0.4080 - accuracy: 0.8315 - val_loss: 0.3620 - val_accuracy: 0.8436\n",
      "Epoch 163/200\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4122 - accuracy: 0.8244 - val_loss: 0.3632 - val_accuracy: 0.8492\n",
      "Epoch 164/200\n",
      "712/712 [==============================] - 0s 56us/step - loss: 0.4083 - accuracy: 0.8244 - val_loss: 0.3625 - val_accuracy: 0.8492\n",
      "Epoch 165/200\n",
      "712/712 [==============================] - 0s 62us/step - loss: 0.4084 - accuracy: 0.8371 - val_loss: 0.3647 - val_accuracy: 0.8492\n",
      "Epoch 166/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4139 - accuracy: 0.8301 - val_loss: 0.3642 - val_accuracy: 0.8324\n",
      "Epoch 167/200\n",
      "712/712 [==============================] - 0s 85us/step - loss: 0.4090 - accuracy: 0.8329 - val_loss: 0.3639 - val_accuracy: 0.8380\n",
      "Epoch 168/200\n",
      "712/712 [==============================] - 0s 42us/step - loss: 0.4223 - accuracy: 0.8258 - val_loss: 0.3629 - val_accuracy: 0.8436\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 36us/step - loss: 0.3981 - accuracy: 0.8301 - val_loss: 0.3630 - val_accuracy: 0.8436\n",
      "Epoch 170/200\n",
      "712/712 [==============================] - 0s 36us/step - loss: 0.4212 - accuracy: 0.8301 - val_loss: 0.3633 - val_accuracy: 0.8492\n",
      "Epoch 171/200\n",
      "712/712 [==============================] - 0s 68us/step - loss: 0.4191 - accuracy: 0.8272 - val_loss: 0.3653 - val_accuracy: 0.8380\n",
      "Epoch 172/200\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4068 - accuracy: 0.8258 - val_loss: 0.3640 - val_accuracy: 0.8492\n",
      "Epoch 173/200\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.4221 - accuracy: 0.8315 - val_loss: 0.3632 - val_accuracy: 0.8492\n",
      "Epoch 174/200\n",
      "712/712 [==============================] - 0s 82us/step - loss: 0.4115 - accuracy: 0.8244 - val_loss: 0.3642 - val_accuracy: 0.8492\n",
      "Epoch 175/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4134 - accuracy: 0.8287 - val_loss: 0.3642 - val_accuracy: 0.8492\n",
      "Epoch 176/200\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4132 - accuracy: 0.8230 - val_loss: 0.3640 - val_accuracy: 0.8492\n",
      "Epoch 177/200\n",
      "712/712 [==============================] - 0s 57us/step - loss: 0.4175 - accuracy: 0.8244 - val_loss: 0.3640 - val_accuracy: 0.8492\n",
      "Epoch 178/200\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4091 - accuracy: 0.8315 - val_loss: 0.3641 - val_accuracy: 0.8492\n",
      "Epoch 179/200\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4063 - accuracy: 0.8258 - val_loss: 0.3645 - val_accuracy: 0.8492\n",
      "Epoch 180/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4030 - accuracy: 0.8244 - val_loss: 0.3641 - val_accuracy: 0.8492\n",
      "Epoch 181/200\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.4107 - accuracy: 0.8188 - val_loss: 0.3644 - val_accuracy: 0.8492\n",
      "Epoch 182/200\n",
      "712/712 [==============================] - 0s 52us/step - loss: 0.4071 - accuracy: 0.8357 - val_loss: 0.3650 - val_accuracy: 0.8436\n",
      "Epoch 183/200\n",
      "712/712 [==============================] - 0s 88us/step - loss: 0.4150 - accuracy: 0.8371 - val_loss: 0.3639 - val_accuracy: 0.8436\n",
      "Epoch 184/200\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.4097 - accuracy: 0.8385 - val_loss: 0.3639 - val_accuracy: 0.8436\n",
      "Epoch 185/200\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4105 - accuracy: 0.8272 - val_loss: 0.3644 - val_accuracy: 0.8492\n",
      "Epoch 186/200\n",
      "712/712 [==============================] - 0s 69us/step - loss: 0.3960 - accuracy: 0.8385 - val_loss: 0.3646 - val_accuracy: 0.8492\n",
      "Epoch 187/200\n",
      "712/712 [==============================] - 0s 70us/step - loss: 0.4122 - accuracy: 0.8272 - val_loss: 0.3637 - val_accuracy: 0.8492\n",
      "Epoch 188/200\n",
      "712/712 [==============================] - 0s 80us/step - loss: 0.4115 - accuracy: 0.8385 - val_loss: 0.3629 - val_accuracy: 0.8492\n",
      "Epoch 189/200\n",
      "712/712 [==============================] - 0s 49us/step - loss: 0.4123 - accuracy: 0.8357 - val_loss: 0.3639 - val_accuracy: 0.8492\n",
      "Epoch 190/200\n",
      "712/712 [==============================] - 0s 60us/step - loss: 0.4062 - accuracy: 0.8371 - val_loss: 0.3639 - val_accuracy: 0.8436\n",
      "Epoch 191/200\n",
      "712/712 [==============================] - 0s 67us/step - loss: 0.4094 - accuracy: 0.8244 - val_loss: 0.3644 - val_accuracy: 0.8492\n",
      "Epoch 192/200\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4051 - accuracy: 0.8301 - val_loss: 0.3641 - val_accuracy: 0.8492\n",
      "Epoch 193/200\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.4125 - accuracy: 0.8301 - val_loss: 0.3653 - val_accuracy: 0.8380\n",
      "Epoch 194/200\n",
      "712/712 [==============================] - 0s 74us/step - loss: 0.4079 - accuracy: 0.8385 - val_loss: 0.3650 - val_accuracy: 0.8380\n",
      "Epoch 195/200\n",
      "712/712 [==============================] - 0s 64us/step - loss: 0.4093 - accuracy: 0.8188 - val_loss: 0.3647 - val_accuracy: 0.8380\n",
      "Epoch 196/200\n",
      "712/712 [==============================] - 0s 73us/step - loss: 0.4109 - accuracy: 0.8272 - val_loss: 0.3646 - val_accuracy: 0.8380\n",
      "Epoch 197/200\n",
      "712/712 [==============================] - 0s 86us/step - loss: 0.4126 - accuracy: 0.8315 - val_loss: 0.3653 - val_accuracy: 0.8380\n",
      "Epoch 198/200\n",
      "712/712 [==============================] - 0s 81us/step - loss: 0.4095 - accuracy: 0.8315 - val_loss: 0.3652 - val_accuracy: 0.8492\n",
      "Epoch 199/200\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.4173 - accuracy: 0.8258 - val_loss: 0.3661 - val_accuracy: 0.8492\n",
      "Epoch 200/200\n",
      "712/712 [==============================] - 0s 95us/step - loss: 0.4126 - accuracy: 0.8216 - val_loss: 0.3658 - val_accuracy: 0.8492\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(df_train, labels, epochs=200, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.45177514076898884,\n",
       "  0.39309358729996496,\n",
       "  0.3740252755873696,\n",
       "  0.3652110329553402,\n",
       "  0.3563672801968772,\n",
       "  0.35392551981537035,\n",
       "  0.34473078826952247,\n",
       "  0.3452646667397888,\n",
       "  0.34240764562644105,\n",
       "  0.3370400592268512,\n",
       "  0.3379396353354001,\n",
       "  0.3333733594617364,\n",
       "  0.33279918841809536,\n",
       "  0.33350712194123083,\n",
       "  0.3290824200021488,\n",
       "  0.3299709251306576,\n",
       "  0.3320056831037532,\n",
       "  0.3290596117353972,\n",
       "  0.3278792289881733,\n",
       "  0.3303832261089506,\n",
       "  0.32796231136974674,\n",
       "  0.32636776424986025,\n",
       "  0.329092842906547,\n",
       "  0.32913270884053003,\n",
       "  0.3281798122981407,\n",
       "  0.3282461379493415,\n",
       "  0.3259411024647718,\n",
       "  0.3271059303143837,\n",
       "  0.3284536605107718,\n",
       "  0.32494979122830503,\n",
       "  0.32867146612212644,\n",
       "  0.32910052433027237,\n",
       "  0.329046291512484,\n",
       "  0.33077548494219117,\n",
       "  0.3294099592629758,\n",
       "  0.3341181107573003,\n",
       "  0.32944817241676694,\n",
       "  0.32757065982125994,\n",
       "  0.32890888282706615,\n",
       "  0.3311065003359118,\n",
       "  0.3301062538137649,\n",
       "  0.32990075747727016,\n",
       "  0.33051564099069414,\n",
       "  0.33295640124622006,\n",
       "  0.32815610937899053,\n",
       "  0.3301473837658014,\n",
       "  0.3312892485930267,\n",
       "  0.3305078693275345,\n",
       "  0.3310767665255669,\n",
       "  0.3307079280721409,\n",
       "  0.33326307247137893,\n",
       "  0.3337372454851033,\n",
       "  0.3298082328375491,\n",
       "  0.32954118496545864,\n",
       "  0.33246335503775315,\n",
       "  0.33087261312500726,\n",
       "  0.33194543196502346,\n",
       "  0.32863443856798735,\n",
       "  0.33399669318225794,\n",
       "  0.32964300418366266,\n",
       "  0.3321814085018701,\n",
       "  0.3349072628514061,\n",
       "  0.3321677073420093,\n",
       "  0.3312749592951556,\n",
       "  0.33704909848767284,\n",
       "  0.33835775217863434,\n",
       "  0.33337096020829077,\n",
       "  0.3423128922225377,\n",
       "  0.3333909065363793,\n",
       "  0.3385175353321949,\n",
       "  0.33457073585947134,\n",
       "  0.3400659966568707,\n",
       "  0.33756763517190624,\n",
       "  0.33273633823381454,\n",
       "  0.33977191549772656,\n",
       "  0.3395966929929882,\n",
       "  0.33766708510548044,\n",
       "  0.3431062998884883,\n",
       "  0.338914037749754,\n",
       "  0.3406226547570202,\n",
       "  0.33737005709602846,\n",
       "  0.3425959207159181,\n",
       "  0.34052617123673085,\n",
       "  0.338688597582572,\n",
       "  0.3407397562398591,\n",
       "  0.3386500381224648,\n",
       "  0.3372620126888073,\n",
       "  0.33933725045712965,\n",
       "  0.342635913517888,\n",
       "  0.3400318017385525,\n",
       "  0.3380396865599648,\n",
       "  0.3423332656062515,\n",
       "  0.3375378072095317,\n",
       "  0.3426069437458528,\n",
       "  0.3435425937342244,\n",
       "  0.3420443934435285,\n",
       "  0.33680892698258663,\n",
       "  0.34295879387655737,\n",
       "  0.34181533012976195,\n",
       "  0.34030112016467406],\n",
       " 'val_accuracy': [0.826815664768219,\n",
       "  0.826815664768219,\n",
       "  0.832402229309082,\n",
       "  0.8491619825363159,\n",
       "  0.8491619825363159,\n",
       "  0.8603351712226868,\n",
       "  0.8547486066818237,\n",
       "  0.8715083599090576,\n",
       "  0.8547486066818237,\n",
       "  0.8659217953681946,\n",
       "  0.8659217953681946,\n",
       "  0.8770949840545654,\n",
       "  0.8659217953681946,\n",
       "  0.8770949840545654,\n",
       "  0.8938547372817993,\n",
       "  0.8715083599090576,\n",
       "  0.8770949840545654,\n",
       "  0.8882681727409363,\n",
       "  0.8826815485954285,\n",
       "  0.8770949840545654,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8882681727409363,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8882681727409363,\n",
       "  0.8826815485954285,\n",
       "  0.8882681727409363,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8770949840545654,\n",
       "  0.8826815485954285,\n",
       "  0.8770949840545654,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8770949840545654,\n",
       "  0.8770949840545654,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8770949840545654,\n",
       "  0.8770949840545654,\n",
       "  0.8826815485954285,\n",
       "  0.8826815485954285,\n",
       "  0.8770949840545654,\n",
       "  0.8826815485954285,\n",
       "  0.8715083599090576,\n",
       "  0.8826815485954285,\n",
       "  0.8770949840545654,\n",
       "  0.8770949840545654,\n",
       "  0.8770949840545654,\n",
       "  0.8826815485954285,\n",
       "  0.8659217953681946,\n",
       "  0.8715083599090576,\n",
       "  0.8715083599090576,\n",
       "  0.8770949840545654,\n",
       "  0.8770949840545654,\n",
       "  0.8826815485954285,\n",
       "  0.8770949840545654,\n",
       "  0.8659217953681946,\n",
       "  0.8770949840545654,\n",
       "  0.8547486066818237,\n",
       "  0.8659217953681946,\n",
       "  0.8659217953681946,\n",
       "  0.8715083599090576,\n",
       "  0.8715083599090576,\n",
       "  0.8659217953681946,\n",
       "  0.8715083599090576,\n",
       "  0.8659217953681946,\n",
       "  0.8547486066818237,\n",
       "  0.8659217953681946,\n",
       "  0.8715083599090576,\n",
       "  0.8715083599090576,\n",
       "  0.8603351712226868,\n",
       "  0.8659217953681946,\n",
       "  0.8715083599090576,\n",
       "  0.8715083599090576,\n",
       "  0.8659217953681946,\n",
       "  0.8659217953681946,\n",
       "  0.8603351712226868,\n",
       "  0.8603351712226868,\n",
       "  0.8547486066818237,\n",
       "  0.8603351712226868,\n",
       "  0.8603351712226868,\n",
       "  0.8547486066818237,\n",
       "  0.8491619825363159,\n",
       "  0.8603351712226868,\n",
       "  0.8603351712226868,\n",
       "  0.8603351712226868,\n",
       "  0.8547486066818237,\n",
       "  0.8603351712226868,\n",
       "  0.8603351712226868,\n",
       "  0.8603351712226868],\n",
       " 'loss': [0.5837802538711033,\n",
       "  0.47392534673883674,\n",
       "  0.444265914766976,\n",
       "  0.43344539169515117,\n",
       "  0.4268282303649388,\n",
       "  0.4196828188521139,\n",
       "  0.41575380657496075,\n",
       "  0.41224868913714807,\n",
       "  0.4104540642727627,\n",
       "  0.40519512436363136,\n",
       "  0.40548949194758127,\n",
       "  0.40371062380544254,\n",
       "  0.39814407738407004,\n",
       "  0.39325480263554646,\n",
       "  0.39155993669220573,\n",
       "  0.38989276430580055,\n",
       "  0.39595804857404043,\n",
       "  0.3910468029841948,\n",
       "  0.38908710104695865,\n",
       "  0.38366364428166594,\n",
       "  0.3880304064643517,\n",
       "  0.3846266939398948,\n",
       "  0.383956308445234,\n",
       "  0.38088923408074327,\n",
       "  0.3751448572016834,\n",
       "  0.380480255973473,\n",
       "  0.37774879276082757,\n",
       "  0.38144401419028806,\n",
       "  0.37724355666824944,\n",
       "  0.3794965697138497,\n",
       "  0.37283882666169926,\n",
       "  0.37133436725380714,\n",
       "  0.376061982820543,\n",
       "  0.38011477569515784,\n",
       "  0.3758790988600656,\n",
       "  0.36851797947722875,\n",
       "  0.3715743049142066,\n",
       "  0.36536815695548325,\n",
       "  0.3702693973364455,\n",
       "  0.3677618543753463,\n",
       "  0.36439541183160934,\n",
       "  0.36226560560505044,\n",
       "  0.3637952087970262,\n",
       "  0.3674386220701625,\n",
       "  0.3664029356134072,\n",
       "  0.359146682064185,\n",
       "  0.3600809487064233,\n",
       "  0.3625962074553029,\n",
       "  0.3574684628944718,\n",
       "  0.3586606249380647,\n",
       "  0.35690264353591405,\n",
       "  0.36070053631000304,\n",
       "  0.36211194315653167,\n",
       "  0.3494303586442819,\n",
       "  0.3579698492971699,\n",
       "  0.3500628819626369,\n",
       "  0.351395226261589,\n",
       "  0.35203062650862704,\n",
       "  0.3575271331192402,\n",
       "  0.3536766372369916,\n",
       "  0.3466653303149041,\n",
       "  0.35414030411270225,\n",
       "  0.3459074092045259,\n",
       "  0.3443326156460837,\n",
       "  0.35097551412796707,\n",
       "  0.3456201195047143,\n",
       "  0.3536456702800279,\n",
       "  0.34614388125666073,\n",
       "  0.35756922638818117,\n",
       "  0.3490828520126557,\n",
       "  0.34640412283747385,\n",
       "  0.342143062125431,\n",
       "  0.3430441758605871,\n",
       "  0.3461926125743416,\n",
       "  0.3467743517307753,\n",
       "  0.3404863686039207,\n",
       "  0.3481536942921328,\n",
       "  0.3392847361189596,\n",
       "  0.3377040289760975,\n",
       "  0.3394840547208036,\n",
       "  0.3385648841268561,\n",
       "  0.3403580989060777,\n",
       "  0.34563642472363587,\n",
       "  0.34583963771884363,\n",
       "  0.34362503986680104,\n",
       "  0.340220277898767,\n",
       "  0.33996337836378077,\n",
       "  0.3428577325317297,\n",
       "  0.3381628213303812,\n",
       "  0.3339875705456466,\n",
       "  0.3306897162051683,\n",
       "  0.33541783054223223,\n",
       "  0.3386963274371758,\n",
       "  0.33457879738861257,\n",
       "  0.3349970190712575,\n",
       "  0.3336226665571834,\n",
       "  0.33431871151656245,\n",
       "  0.3413904851742005,\n",
       "  0.33809549989325277,\n",
       "  0.3261716399299964],\n",
       " 'accuracy': [0.7078652,\n",
       "  0.7977528,\n",
       "  0.8174157,\n",
       "  0.8146067,\n",
       "  0.81601125,\n",
       "  0.8258427,\n",
       "  0.8272472,\n",
       "  0.8258427,\n",
       "  0.8230337,\n",
       "  0.8272472,\n",
       "  0.8328652,\n",
       "  0.8272472,\n",
       "  0.83707863,\n",
       "  0.83146065,\n",
       "  0.83426964,\n",
       "  0.8426966,\n",
       "  0.83848315,\n",
       "  0.8398876,\n",
       "  0.8328652,\n",
       "  0.84410113,\n",
       "  0.84129214,\n",
       "  0.83567417,\n",
       "  0.83848315,\n",
       "  0.8398876,\n",
       "  0.84410113,\n",
       "  0.83848315,\n",
       "  0.8497191,\n",
       "  0.8455056,\n",
       "  0.8469101,\n",
       "  0.8426966,\n",
       "  0.85393256,\n",
       "  0.8525281,\n",
       "  0.85393256,\n",
       "  0.8525281,\n",
       "  0.8483146,\n",
       "  0.8497191,\n",
       "  0.8511236,\n",
       "  0.85393256,\n",
       "  0.8525281,\n",
       "  0.8525281,\n",
       "  0.8525281,\n",
       "  0.85674155,\n",
       "  0.8581461,\n",
       "  0.86095506,\n",
       "  0.8511236,\n",
       "  0.85674155,\n",
       "  0.8455056,\n",
       "  0.8525281,\n",
       "  0.86095506,\n",
       "  0.86376405,\n",
       "  0.8623595,\n",
       "  0.8553371,\n",
       "  0.85674155,\n",
       "  0.8679775,\n",
       "  0.8553371,\n",
       "  0.86095506,\n",
       "  0.85674155,\n",
       "  0.86376405,\n",
       "  0.85955054,\n",
       "  0.8553371,\n",
       "  0.8581461,\n",
       "  0.85674155,\n",
       "  0.86095506,\n",
       "  0.85674155,\n",
       "  0.8623595,\n",
       "  0.85955054,\n",
       "  0.85674155,\n",
       "  0.86376405,\n",
       "  0.8553371,\n",
       "  0.86095506,\n",
       "  0.869382,\n",
       "  0.86376405,\n",
       "  0.86657304,\n",
       "  0.8735955,\n",
       "  0.86095506,\n",
       "  0.8679775,\n",
       "  0.8679775,\n",
       "  0.8623595,\n",
       "  0.86095506,\n",
       "  0.869382,\n",
       "  0.85955054,\n",
       "  0.86095506,\n",
       "  0.86657304,\n",
       "  0.86657304,\n",
       "  0.85955054,\n",
       "  0.8623595,\n",
       "  0.86376405,\n",
       "  0.8679775,\n",
       "  0.875,\n",
       "  0.8679775,\n",
       "  0.8679775,\n",
       "  0.872191,\n",
       "  0.86657304,\n",
       "  0.86657304,\n",
       "  0.8623595,\n",
       "  0.86657304,\n",
       "  0.86376405,\n",
       "  0.85674155,\n",
       "  0.875,\n",
       "  0.8581461]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Survived'] = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.015955</td>\n",
       "      <td>-0.027888</td>\n",
       "      <td>-0.037361</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>-0.027901</td>\n",
       "      <td>0.107035</td>\n",
       "      <td>-0.035022</td>\n",
       "      <td>0.398984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.005864</td>\n",
       "      <td>0.949229</td>\n",
       "      <td>0.991127</td>\n",
       "      <td>1.038673</td>\n",
       "      <td>0.959595</td>\n",
       "      <td>1.049394</td>\n",
       "      <td>1.005160</td>\n",
       "      <td>0.331033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-2.535007</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>-1.546098</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>-1.546098</td>\n",
       "      <td>0.120028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>0.333474</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0.261239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.851591</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>1.124265</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0.698427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>3.762120</td>\n",
       "      <td>3.241014</td>\n",
       "      <td>2.705848</td>\n",
       "      <td>5.758637</td>\n",
       "      <td>2.458182</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0.994697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sex       Title    AgeGroup        Fare   Relatives    Embarked  \\\n",
       "count  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000   \n",
       "mean     0.015955   -0.027888   -0.037361    0.006184   -0.027901    0.107035   \n",
       "std      1.005864    0.949229    0.991127    1.038673    0.959595    1.049394   \n",
       "min     -0.743497   -0.715617   -2.535007   -1.248109   -0.558346   -0.603436   \n",
       "25%     -0.743497   -0.715617   -1.091002   -1.248109   -0.558346   -0.603436   \n",
       "50%     -0.743497   -0.715617    0.353004    0.333474   -0.558346   -0.603436   \n",
       "75%      1.344995    0.851591    0.353004    1.124265    0.073352    0.927373   \n",
       "max      1.344995    3.762120    3.241014    2.705848    5.758637    2.458182   \n",
       "\n",
       "           Pclass    Survived  \n",
       "count  418.000000  418.000000  \n",
       "mean    -0.035022    0.398984  \n",
       "std      1.005160    0.331033  \n",
       "min     -1.546098    0.000210  \n",
       "25%     -1.546098    0.120028  \n",
       "50%      0.841916    0.261239  \n",
       "75%      0.841916    0.698427  \n",
       "max      0.841916    0.994697  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Survived'] = df_test['Survived'].apply(lambda x: round(x,0)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>2.458182</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>1.797009</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>2.458182</td>\n",
       "      <td>-0.352091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1.344995</td>\n",
       "      <td>2.866573</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>1.915057</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>-1.546098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>-1.248109</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>-0.715617</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>-0.457318</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.603436</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>-0.743497</td>\n",
       "      <td>1.971025</td>\n",
       "      <td>-1.091002</td>\n",
       "      <td>0.333474</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>0.927373</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sex     Title  AgeGroup      Fare  Relatives  Embarked  \\\n",
       "PassengerId                                                                \n",
       "892         -0.743497 -0.715617  0.353004 -1.248109  -0.558346  2.458182   \n",
       "893          1.344995  0.179930  1.797009 -1.248109   0.073352 -0.603436   \n",
       "894         -0.743497 -0.715617 -1.091002 -0.457318  -0.558346  2.458182   \n",
       "895         -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "896          1.344995  0.179930  0.353004 -0.457318   0.705051 -0.603436   \n",
       "...               ...       ...       ...       ...        ...       ...   \n",
       "1305        -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "1306         1.344995  2.866573  0.353004  1.915057  -0.558346  0.927373   \n",
       "1307        -0.743497 -0.715617  0.353004 -1.248109  -0.558346 -0.603436   \n",
       "1308        -0.743497 -0.715617 -1.091002 -0.457318  -0.558346 -0.603436   \n",
       "1309        -0.743497  1.971025 -1.091002  0.333474   0.705051  0.927373   \n",
       "\n",
       "               Pclass  Survived  \n",
       "PassengerId                      \n",
       "892          0.841916         0  \n",
       "893          0.841916         1  \n",
       "894         -0.352091         0  \n",
       "895          0.841916         0  \n",
       "896          0.841916         1  \n",
       "...               ...       ...  \n",
       "1305         0.841916         0  \n",
       "1306        -1.546098         1  \n",
       "1307         0.841916         0  \n",
       "1308         0.841916         0  \n",
       "1309         0.841916         0  \n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df_test.loc[:,['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results_NN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This results in a 77% accuracy in Kaggle. Let's try to improve the accuracy with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to find the optimum number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, activation='relu', input_shape=(7,)))\n",
    "    # model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # output layer\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] batch_size=16, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... batch_size=16, epochs=50, total=   6.4s\n",
      "[CV] batch_size=16, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... batch_size=16, epochs=50, total=   6.1s\n",
      "[CV] batch_size=16, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=16, epochs=50, total=   6.3s\n",
      "[CV] batch_size=16, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=16, epochs=50, total=   6.3s\n",
      "[CV] batch_size=16, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=16, epochs=50, total=   6.4s\n",
      "[CV] batch_size=16, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=16, epochs=100, total=  11.2s\n",
      "[CV] batch_size=16, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=16, epochs=100, total=  10.5s\n",
      "[CV] batch_size=16, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=16, epochs=100, total=  11.2s\n",
      "[CV] batch_size=16, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=16, epochs=100, total=  10.2s\n",
      "[CV] batch_size=16, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=16, epochs=100, total=  10.6s\n",
      "[CV] batch_size=32, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=32, epochs=50, total=   4.3s\n",
      "[CV] batch_size=32, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=32, epochs=50, total=   4.5s\n",
      "[CV] batch_size=32, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=32, epochs=50, total=   4.1s\n",
      "[CV] batch_size=32, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=32, epochs=50, total=   3.9s\n",
      "[CV] batch_size=32, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=32, epochs=50, total=   3.7s\n",
      "[CV] batch_size=32, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=32, epochs=100, total=   5.3s\n",
      "[CV] batch_size=32, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=32, epochs=100, total=   6.4s\n",
      "[CV] batch_size=32, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=32, epochs=100, total=   6.0s\n",
      "[CV] batch_size=32, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=32, epochs=100, total=   6.3s\n",
      "[CV] batch_size=32, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=32, epochs=100, total=   7.0s\n",
      "[CV] batch_size=64, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=64, epochs=50, total=   3.8s\n",
      "[CV] batch_size=64, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=64, epochs=50, total=   3.3s\n",
      "[CV] batch_size=64, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=64, epochs=50, total=   3.2s\n",
      "[CV] batch_size=64, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=64, epochs=50, total=   3.1s\n",
      "[CV] batch_size=64, epochs=50 ........................................\n",
      "[CV] ......................... batch_size=64, epochs=50, total=   3.3s\n",
      "[CV] batch_size=64, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=64, epochs=100, total=   4.4s\n",
      "[CV] batch_size=64, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=64, epochs=100, total=   4.8s\n",
      "[CV] batch_size=64, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=64, epochs=100, total=   4.5s\n",
      "[CV] batch_size=64, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=64, epochs=100, total=   4.4s\n",
      "[CV] batch_size=64, epochs=100 .......................................\n",
      "[CV] ........................ batch_size=64, epochs=100, total=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.9min finished\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [16, 32, 64]\n",
    "epochs = [50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=2)\n",
    "grid_result = grid.fit(df_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.810313 using {'batch_size': 64, 'epochs': 50}\n",
      "0.806949 (0.029487) with: {'batch_size': 16, 'epochs': 50}\n",
      "0.805850 (0.021938) with: {'batch_size': 16, 'epochs': 100}\n",
      "0.808091 (0.022766) with: {'batch_size': 32, 'epochs': 50}\n",
      "0.803597 (0.019401) with: {'batch_size': 32, 'epochs': 100}\n",
      "0.810313 (0.015784) with: {'batch_size': 64, 'epochs': 50}\n",
      "0.801343 (0.012659) with: {'batch_size': 64, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Titanic-cleaned-NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
